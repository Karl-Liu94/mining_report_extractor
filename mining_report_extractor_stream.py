import os
import json
import pathlib
from typing import Optional, List, Dict, Any, Tuple
from abc import ABC, abstractmethod
from pydantic import BaseModel


# ========== Pydantic æ•°æ®æ¨¡å‹ ==========
class ReportInfo(BaseModel):
    """æŠ¥å‘Šä¿¡æ¯æ¨¡å‹"""
    æŠ¥å‘Šåç§°: Optional[str] = None
    ç¼–åˆ¶å•ä½: Optional[str] = None
    ç¼–åˆ¶æ—¥æœŸ: Optional[str] = None


class MiningRightsInfo(BaseModel):
    """çŸ¿æƒä¿¡æ¯æ¨¡å‹"""
    çŸ¿æƒåç§°: Optional[str] = None
    çŸ¿æƒä½ç½®: Optional[str] = None
    å‹˜æŸ¥ç¨‹åº¦: Optional[str] = None  # æ™®æŸ¥/è¯¦æŸ¥/å‹˜æ¢
    çŸ¿æƒç±»å‹: Optional[str] = None  # æ¢çŸ¿æƒ/é‡‡çŸ¿æƒ
    çŸ¿æƒç¼–å·: Optional[str] = None
    çŸ¿æƒèµ·å§‹æ—¥æœŸ: Optional[str] = None
    çŸ¿æƒæˆªæ­¢æ—¥æœŸ: Optional[str] = None
    ç”Ÿäº§è§„æ¨¡: Optional[str] = None
    çŸ¿åŒºé¢ç§¯: Optional[str] = None
    çŸ¿åŒºæµ·æ‹”: Optional[str] = None
    ä»¥å¾€å‹˜æŸ¥å·¥ä½œ: Optional[str] = None


class ResourceQuantityDetail(BaseModel):
    """èµ„æºé‡è¯¦ç»†ä¿¡æ¯æ¨¡å‹"""
    çŸ¿çŸ³é‡: Optional[str] = None
    é‡‘å±é‡: Optional[str] = None
    å“ä½: Optional[str] = None


class ResourceCategory(BaseModel):
    """èµ„æºé‡ç±»åˆ«æ¨¡å‹"""
    æ¨æ–­èµ„æºé‡: Optional[ResourceQuantityDetail] = None
    æ§åˆ¶èµ„æºé‡: Optional[ResourceQuantityDetail] = None
    æ¢æ˜èµ„æºé‡: Optional[ResourceQuantityDetail] = None
    æ€»è®¡: Optional[ResourceQuantityDetail] = None


class ResourceInfo(BaseModel):
    """èµ„æºä¿¡æ¯æ¨¡å‹"""
    çŸ¿ç§: Optional[str] = None
    èµ„æºé‡æƒ…å†µ: Optional[ResourceCategory] = None


class OreBodyDistribution(BaseModel):
    """çŸ¿ä½“åˆ†å¸ƒæƒ…å†µä¿¡æ¯æ¨¡å‹"""
    çŸ¿ä½“ç¼–å·: Optional[str] = None
    çŸ¿ä½“åç§°: Optional[str] = None
    çŸ¿ä½“é•¿åº¦: Optional[str] = None
    çŸ¿ä½“å®½åº¦: Optional[str] = None
    çŸ¿ä½“åšåº¦: Optional[str] = None
    çŸ¿ä½“èµ°å‘: Optional[str] = None
    çŸ¿ä½“å€¾è§’: Optional[str] = None
    çŸ¿ä½“é¢ç§¯: Optional[str] = None
    çŸ¿ä½“ä½“ç§¯: Optional[str] = None
    çŸ¿ä½“é‡‘å±é‡: Optional[str] = None
    çŸ¿ä½“çŸ¿çŸ³é‡: Optional[str] = None
    çŸ¿ä½“å“ä½: Optional[str] = None


class MiningReport(BaseModel):
    """çŸ¿å±±å‚¨é‡æ ¸å®æŠ¥å‘Šå®Œæ•´æ¨¡å‹"""
    æŠ¥å‘Šä¿¡æ¯: Optional[ReportInfo] = None
    çŸ¿æƒä¿¡æ¯: Optional[MiningRightsInfo] = None
    èµ„æºä¿¡æ¯: Optional[List[ResourceInfo]] = None
    çŸ¿ä½“åˆ†å¸ƒ: Optional[List[OreBodyDistribution]] = None
    å…¶å®ƒä¿¡æ¯: Optional[str] = None


# ========== æç¤ºè¯é…ç½® ==========
EXTRACTION_PROMPT = """
ä½ æ˜¯ä¸€ååœ°è´¨å’ŒçŸ¿ä¸šé¢†åŸŸçš„ä¸“å®¶ï¼Œè¯·ä»”ç»†åˆ†æè¿™ä¸ªçŸ¿å±±å‚¨é‡æ ¸å®æŠ¥å‘ŠPDFæ–‡æ¡£ï¼ŒæŒ‰ç…§ä»¥ä¸‹ç»“æ„æå–ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

## æŠ¥å‘Šä¿¡æ¯
- æŠ¥å‘Šåç§°ï¼šæŠ¥å‘Šçš„å®Œæ•´åç§°ï¼Œé€šå¸¸åœ¨é¦–é¡µæˆ–æ ‡é¢˜ä¸­
- ç¼–åˆ¶å•ä½ï¼šç¼–åˆ¶è¯¥æŠ¥å‘Šçš„æœºæ„æˆ–å…¬å¸åç§°ï¼ˆæ³¨æ„ï¼šä¸è¦ä¸å§”æ‰˜å…¬å¸æ··æ·†ï¼Œä¸€èˆ¬æ­£æ–‡ä¸­ä¼šæ³¨æ˜ï¼ŒAå…¬å¸å§”æ‰˜Bå…¬å¸/åœ°è´¨é˜Ÿ/å•ä½å¯¹xxå¼€å±•å‹˜æ¢å·¥ä½œï¼Œç¼–åˆ¶äº†æœ¬æŠ¥å‘Šï¼Œè¿™ä¸ªBå…¬å¸/åœ°è´¨é˜Ÿ/å•ä½æ‰æ˜¯ç¼–åˆ¶å•ä½ï¼‰
- ç¼–åˆ¶æ—¥æœŸï¼šæŠ¥å‘Šçš„ç¼–åˆ¶æ—¥æœŸ

## çŸ¿æƒä¿¡æ¯
- çŸ¿æƒåç§°ï¼šè¯¥æŠ¥å‘Šæ‰€è°ƒæŸ¥çš„çŸ¿æƒä¸»ä½“åç§°
- çŸ¿æƒä½ç½®ï¼šçŸ¿æƒçš„åœ°ç†ä½ç½®
- å‹˜æŸ¥ç¨‹åº¦ï¼šæœ¬æ¬¡å‚¨é‡æ ¸å®çš„å‹˜æŸ¥ç¨‹åº¦ï¼Œæœ‰ä¸”ä»…æœ‰ä»¥ä¸‹ä¸‰ç§ç±»å‹ï¼ˆå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›nullï¼‰ï¼š
  * æ™®æŸ¥
  * è¯¦æŸ¥  
  * å‹˜æ¢
- çŸ¿æƒç±»å‹ï¼šæœ‰ä¸”ä»…æœ‰ä»¥ä¸‹ä¸¤ç§ç±»å‹ï¼ˆå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›nullï¼‰ï¼š
  * æ¢çŸ¿æƒ
  * é‡‡çŸ¿æƒ
- çŸ¿æƒç¼–å·ï¼šçŸ¿æƒçš„å®˜æ–¹ç¼–å·
- çŸ¿æƒèµ·å§‹æ—¥æœŸï¼šçŸ¿æƒçš„å¼€å§‹æ—¥æœŸ
- çŸ¿æƒæˆªæ­¢æ—¥æœŸï¼šçŸ¿æƒçš„ç»“æŸæ—¥æœŸ
- ç”Ÿäº§è§„æ¨¡ï¼šçŸ¿å±±çš„ç”Ÿäº§è§„æ¨¡ï¼Œå¦‚"100ä¸‡å¨/å¹´"ã€"50ä¸‡å¨/å¹´"ç­‰ï¼Œä»…é‡‡çŸ¿è¯æ‰æœ‰ï¼Œæ¢çŸ¿è¯å¯è¿”å›null
- çŸ¿åŒºé¢ç§¯ï¼šçŸ¿åŒºçš„æ€»é¢ç§¯ï¼ˆåŒ…å«æ•°å€¼å’Œå•ä½ï¼‰
- çŸ¿åŒºæµ·æ‹”ï¼šçŸ¿åŒºçš„æµ·æ‹”é«˜åº¦
- ä»¥å¾€å‹˜æŸ¥å·¥ä½œ:è¿‡å»åœ°è´¨å·¥ä½œçš„ç®€è¦æ€»ç»“

## èµ„æºä¿¡æ¯
- çŸ¿ç§ï¼šè¿”å›å®Œæ•´æ ¼å¼å¦‚"é‡‘çŸ¿"ã€"é“œçŸ¿"ã€"é“¶çŸ¿"ï¼Œä¸è¦åªè¿”å›"é‡‘"ã€"é“œ"ã€"é“¶"
- èµ„æºé‡æƒ…å†µï¼šå¯¹äºæ¯ä¸ªçŸ¿ç§ï¼ˆåŒ…æ‹¬ä¸»çŸ¿ç§å’Œä¼´ç”ŸçŸ¿ç§ï¼‰ï¼Œéƒ½è¦å°è¯•æŒ‰ä»¥ä¸‹ç±»åˆ«åˆ†åˆ«æå–ï¼š
  * æ¨æ–­èµ„æºé‡ï¼ˆå¦‚æœæŠ¥å‘Šä¸­é‡åˆ°333èµ„æºé‡ï¼Œè®¡å…¥è¿™è¯¥ç±»åˆ«ï¼‰
  * æ§åˆ¶èµ„æºé‡ï¼ˆå¦‚æœæŠ¥å‘Šä¸­é‡åˆ°332èµ„æºé‡ï¼Œè®¡å…¥è¿™è¯¥ç±»åˆ«ï¼‰
  * æ¢æ˜èµ„æºé‡ï¼ˆå¦‚æœæŠ¥å‘Šä¸­é‡åˆ°331èµ„æºé‡ã€1ã€2å¼€å¤´çš„èµ„æºé‡ï¼Œå¦‚122bã€111ç­‰è®¡å…¥è¿™è¯¥ç±»åˆ«ï¼‰
  * æ€»è®¡ï¼ˆå°†ä¸Šè¿°èµ„æºé‡åŠ æ€»ï¼Œè¡¨ç¤ºè¯¥çŸ¿ç§çš„æ‰€æœ‰èµ„æºæƒ…å†µï¼‰

**é‡è¦è¯´æ˜ï¼š**
1. å¯¹äºæ¯ä¸ªçŸ¿ç§ï¼ˆæ— è®ºæ˜¯ä¸»çŸ¿ç§è¿˜æ˜¯ä¼´ç”ŸçŸ¿ç§ï¼‰ï¼Œéƒ½è¦å°è¯•æå–åˆ†ç±»èµ„æºé‡æ•°æ®
2. å¦‚æœæŠ¥å‘Šä¸­æŸä¸ªçŸ¿ç§åªæä¾›äº†æ€»è®¡æ•°æ®è€Œæ²¡æœ‰åˆ†ç±»æ•°æ®ï¼Œé‚£ä¹ˆåˆ†ç±»å­—æ®µä¹Ÿè¦ä¿ç•™ï¼Œå€¼ä¸ºnullå³å¯ï¼Œè€Œä¸åªå¡«å†™æ€»è®¡å­—æ®µ
3. å¦‚æœæŠ¥å‘Šä¸­æŸä¸ªçŸ¿ç§æœ‰åˆ†ç±»æ•°æ®ï¼Œè¯·åŠ¡å¿…æå–æ‰€æœ‰å¯ç”¨çš„åˆ†ç±»ä¿¡æ¯
4. ä¸Šè¿°èµ„æºé‡å‡è¿”å›ä¿æœ‰èµ„æºé‡

å¯¹äºæ¯ä¸ªèµ„æºé‡ç±»åˆ«ï¼Œè¯·æå–ï¼š
- çŸ¿çŸ³é‡ï¼šè¿”å›æ•°å€¼å’Œå•ä½ï¼Œå¦‚"1000åƒå…‹"ã€"120ä¸‡å¨"ï¼ˆæ³¨æ„ï¼šä¼´ç”ŸçŸ¿ç§å¯èƒ½ä¸ä¸»çŸ¿ç§å…±äº«çŸ¿çŸ³é‡ï¼‰
- é‡‘å±é‡ï¼šè¿”å›æ•°å€¼å’Œå•ä½ï¼Œå¦‚"1000åƒå…‹"ã€"120ä¸‡å¨"  
- å“ä½ï¼šè¿”å›å¦‚"6%"æˆ–"2.7å…‹/å¨"çš„æ ¼å¼

å¦‚æœæŠ¥å‘Šä¸­å‡ºç°å¤šä¸ªçŸ¿ç§æˆ–ä¼´ç”ŸçŸ¿ï¼Œè¯·ä¸€å¹¶è¿”å›ï¼Œæ¯ä¸ªçŸ¿ç§å•ç‹¬ç»Ÿè®¡

## çŸ¿ä½“åˆ†å¸ƒ
- çŸ¿ä½“ç¼–å·ï¼šçŸ¿ä½“çš„ç¼–å·
- çŸ¿ä½“åç§°ï¼šçŸ¿ä½“çš„åç§°
- çŸ¿ä½“é•¿åº¦ï¼šçŸ¿ä½“çš„é•¿åº¦
- çŸ¿ä½“å®½åº¦ï¼šçŸ¿ä½“çš„å®½åº¦
- çŸ¿ä½“åšåº¦ï¼šçŸ¿ä½“çš„åšåº¦
- çŸ¿ä½“èµ°å‘ï¼šçŸ¿ä½“çš„èµ°å‘
- çŸ¿ä½“å€¾è§’ï¼šçŸ¿ä½“çš„å€¾è§’
- çŸ¿ä½“é¢ç§¯ï¼šçŸ¿ä½“çš„é¢ç§¯
- çŸ¿ä½“ä½“ç§¯ï¼šçŸ¿ä½“çš„ä½“ç§¯
- çŸ¿ä½“é‡‘å±é‡ï¼šçŸ¿ä½“çš„é‡‘å±é‡
- çŸ¿ä½“çŸ¿çŸ³é‡ï¼šçŸ¿ä½“çš„çŸ¿çŸ³é‡
- çŸ¿ä½“å“ä½ï¼šçŸ¿ä½“çš„å“ä½

**é‡è¦è¯´æ˜ï¼š**
ä»¥ä¸Šä¿¡æ¯æŠ¥å‘Šä¸­å¯èƒ½æœ‰æè¿°ï¼Œå¯èƒ½æ²¡æœ‰æè¿°ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°æè¿°åˆ™è¿”å›nullï¼Œåˆ‡ä¸å¯æ²¡æœ‰æ ¹æ®åœ°èƒ¡ä¹±ç¼–é€ ï¼

## å…¶å®ƒä¿¡æ¯
æå–ä»»ä½•ä¸Šè¿°æœªæåˆ°ä½†ä½ è®¤ä¸ºæœ‰ä»·å€¼çš„ä¿¡æ¯

å¦‚æœæŸäº›ä¿¡æ¯åœ¨æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ï¼Œè¯·åœ¨å¯¹åº”å­—æ®µå¡«å…¥nullã€‚
è¯·ä»”ç»†é˜…è¯»æ–‡æ¡£å†…å®¹ï¼Œç‰¹åˆ«æ³¨æ„èµ„æºé‡ç»Ÿè®¡è¡¨æ ¼ï¼Œç¡®ä¿æå–çš„ä¿¡æ¯å‡†ç¡®å®Œæ•´ã€‚
"""

CONVERSATION_INSTRUCTIONS = """
ä½ æ˜¯ä¸€ååœ°è´¨å’ŒçŸ¿ä¸šé¢†åŸŸçš„ä¸“å®¶ï¼Œè¯·ä½ ä»”ç»†é˜…è¯»æŠ¥å‘Šå†…å®¹ï¼Œè®¤çœŸå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œ
æ³¨æ„ç­”æ¡ˆéœ€è¦æ¡ç†æ¸…æ™°ï¼Œå¦‚æœé‡åˆ°ä¸çŸ¥é“æˆ–è€…æŠ¥å‘Šä¸­æ²¡æœ‰çš„é—®é¢˜å¯ç›´è¨€ä¸çŸ¥é“ï¼Œ
åˆ‡ä¸å¯èƒ¡ç¼–ä¹±é€ ï¼ä¼˜å…ˆä¿è¯ç­”æ¡ˆçš„æ­£ç¡®æ€§
"""


# ========== é…ç½®å¸¸é‡ ==========
GEMINI_MODELS = ["gemini-2.5-flash", "gemini-2.5-pro"]
OPENAI_MODELS = ["o4-mini", "o3", "gpt-4.1-nano"]
EXIT_COMMANDS = ['exit', 'quit', 'é€€å‡º', 'ç»“æŸ']
CONFIRM_CHOICES = ['y', 'yes', 'æ˜¯', 'å¥½']
DENY_CHOICES = ['n', 'no', 'å¦', 'ä¸']


# ========== æŠ½è±¡åŸºç±» ==========
class BaseMiningReportExtractor(ABC):
    """çŸ¿å±±æŠ¥å‘Šæå–å™¨æŠ½è±¡åŸºç±»"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = None):
        self.api_key = api_key
        self.model = model
        self.prompt = EXTRACTION_PROMPT
    
    def _get_file_size_mb(self, file_path: str) -> float:
        """è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
        file_size_bytes = pathlib.Path(file_path).stat().st_size
        return file_size_bytes / (1024 * 1024)
    
    @abstractmethod
    def extract_from_file(self, file_path: str) -> MiningReport:
        """ä»PDFæ–‡ä»¶æå–ä¿¡æ¯"""
        pass
    
    def save_result(self, result: MiningReport, output_path: str) -> bool:
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            result_dict = result.model_dump(exclude_none=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result_dict, f, ensure_ascii=False, indent=2)
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def print_summary(self, result: MiningReport) -> None:
        """æ‰“å°æå–ç»“æœæ‘˜è¦"""
        print("\n" + "="*50)
        print("ğŸ“Š çŸ¿å±±å‚¨é‡æ ¸å®æŠ¥å‘Šä¿¡æ¯æ‘˜è¦")
        print("="*50)
        
        # æŠ¥å‘Šä¿¡æ¯
        if result.æŠ¥å‘Šä¿¡æ¯:
            print(f"\nğŸ“‹ æŠ¥å‘Šä¿¡æ¯:")
            for field, value in result.æŠ¥å‘Šä¿¡æ¯.model_dump().items():
                print(f"  â€¢ {field}: {value or 'N/A'}")
        
        # çŸ¿æƒä¿¡æ¯
        if result.çŸ¿æƒä¿¡æ¯:
            print(f"\nâ›ï¸  çŸ¿æƒä¿¡æ¯:")
            for field, value in result.çŸ¿æƒä¿¡æ¯.model_dump().items():
                print(f"  â€¢ {field}: {value or 'N/A'}")
        
        # èµ„æºä¿¡æ¯ï¼ˆç®€åŒ–æ˜¾ç¤ºï¼‰
        if result.èµ„æºä¿¡æ¯:
            print(f"\nğŸ’ èµ„æºä¿¡æ¯:")
            for idx, resource in enumerate(result.èµ„æºä¿¡æ¯, 1):
                if len(result.èµ„æºä¿¡æ¯) > 1:
                    print(f"\n  ã€çŸ¿ç§ {idx}ã€‘")
                print(f"  â€¢ çŸ¿ç§: {resource.çŸ¿ç§ or 'N/A'}")
                
                if resource.èµ„æºé‡æƒ…å†µ and resource.èµ„æºé‡æƒ…å†µ.æ€»è®¡:
                    total = resource.èµ„æºé‡æƒ…å†µ.æ€»è®¡
                    print(f"  â€¢ èµ„æºé‡æ€»è®¡:")
                    print(f"    - çŸ¿çŸ³é‡: {total.çŸ¿çŸ³é‡ or 'N/A'}")
                    print(f"    - é‡‘å±é‡: {total.é‡‘å±é‡ or 'N/A'}")
                    print(f"    - å“ä½: {total.å“ä½ or 'N/A'}")
        
        # å…¶å®ƒä¿¡æ¯
        if result.å…¶å®ƒä¿¡æ¯:
            print(f"\nğŸ“ å…¶å®ƒä¿¡æ¯:")
            print(f"  {result.å…¶å®ƒä¿¡æ¯}")
        
        print("\n" + "="*50)


# ========== Gemini å®ç° ==========
class GeminiMiningReportExtractor(BaseMiningReportExtractor):
    """åŸºäºGeminiçš„çŸ¿å±±æŠ¥å‘Šæå–å™¨"""
    
    FILE_SIZE_THRESHOLD = 20 * 1024 * 1024  # 20MB
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-2.5-flash", env_file: str = ".env"):
        super().__init__(api_key, model)
        
        try:
            from google import genai
            from google.genai import types
            from dotenv import load_dotenv
            self.genai = genai
            self.types = types
            load_dotenv(env_file)
        except ImportError:
            raise ImportError("è¯·å®‰è£…å¿…éœ€åŒ…: pip install google-genai python-dotenv")
        
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            raise ValueError("è¯·æä¾›GEMINI_API_KEYç¯å¢ƒå˜é‡æˆ–ç›´æ¥ä¼ å…¥api_keyå‚æ•°")
        
        self.client = genai.Client(api_key=self.api_key)
    
    def extract_from_file(self, file_path: str, use_file_api: Optional[bool] = None) -> MiningReport:
        """ä»PDFæ–‡ä»¶æå–ä¿¡æ¯"""
        filepath = pathlib.Path(file_path)
        if not filepath.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        file_size_mb = self._get_file_size_mb(file_path)
        
        # è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦ä½¿ç”¨File API
        if use_file_api is None:
            use_file_api = filepath.stat().st_size > self.FILE_SIZE_THRESHOLD
        
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
        
        if use_file_api:
            print(f"ğŸ“¤ ä½¿ç”¨File APIä¸Šä¼ ï¼ˆæ–‡ä»¶å¤§å°è¶…è¿‡{self.FILE_SIZE_THRESHOLD/(1024*1024):.0f}MBé˜ˆå€¼ï¼‰")
            print("â³ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ°GeminiæœåŠ¡å™¨...")
            uploaded_file = self.client.files.upload(file=filepath)
            file_content = uploaded_file
            print("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ")
        else:
            print(f"ğŸ“¤ ä½¿ç”¨ç›´æ¥å­—èŠ‚ä¸Šä¼ ")
            file_content = self.types.Part.from_bytes(
                data=filepath.read_bytes(),
                mime_type='application/pdf',
            )
        
        print("ğŸ” æ­£åœ¨åˆ†ææ–‡æ¡£å†…å®¹...")
        response = self.client.models.generate_content(
            model=self.model,
            contents=[file_content, self.prompt],
            config={
                "response_mime_type": "application/json",
                "response_schema": MiningReport,
            }
        )
        
        result = MiningReport.model_validate_json(response.text)
        print("âœ… æ–‡æ¡£åˆ†æå®Œæˆ")
        return result


# ========== OpenAI å®ç°ï¼ˆå¸¦æµå¼å¯¹è¯åŠŸèƒ½ï¼‰ ==========
class OpenAIMiningReportExtractorWithStreamConversation(BaseMiningReportExtractor):
    """åŸºäºOpenAIçš„çŸ¿å±±æŠ¥å‘Šæå–å™¨ï¼ˆå¸¦æµå¼å¯¹è¯åŠŸèƒ½ï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "o4-mini", env_file: str = ".env"):
        super().__init__(api_key, model)
        
        try:
            from openai import OpenAI
            from dotenv import load_dotenv
            self.OpenAI = OpenAI
            load_dotenv(env_file)
        except ImportError:
            raise ImportError("è¯·å®‰è£…å¿…éœ€åŒ…: pip install openai python-dotenv")
        
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("è¯·æä¾›OPENAI_API_KEYç¯å¢ƒå˜é‡æˆ–ç›´æ¥ä¼ å…¥api_keyå‚æ•°")
        
        self.client = OpenAI(api_key=self.api_key)
        self.file_id = None  # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶ID
        self.initial_response_id = None  # ä¿å­˜åˆå§‹æå–å“åº”çš„ID
    
    def _upload_file(self, file_path: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ°OpenAI"""
        print("ğŸ“¤ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ°OpenAIæœåŠ¡å™¨...")
        with open(file_path, "rb") as f:
            file = self.client.files.create(file=f, purpose="user_data")
        print("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ")
        return file.id
    
    def extract_from_file(self, file_path: str) -> MiningReport:
        """ä»PDFæ–‡ä»¶æå–ä¿¡æ¯"""
        filepath = pathlib.Path(file_path)
        if not filepath.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        file_size_mb = self._get_file_size_mb(file_path)
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
        
        self.file_id = self._upload_file(file_path)
        
        print("ğŸ” æ­£åœ¨åˆ†ææ–‡æ¡£å†…å®¹...")
        response = self.client.responses.parse(
            model=self.model,
            input=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_file",
                            "file_id": self.file_id,
                        },
                        {
                            "type": "input_text",
                            "text": self.prompt,
                        },
                    ]
                }
            ],
            text_format=MiningReport,
        )
        
        # ä¿å­˜åˆå§‹å“åº”IDï¼Œç”¨äºåç»­å¯¹è¯
        self.initial_response_id = response.id
        
        result = response.output_parsed
        print("âœ… æ–‡æ¡£åˆ†æå®Œæˆ")
        return result
    
    def start_conversation(self):
        """å¼€å§‹å¯¹è¯æ¨¡å¼"""
        if not self.initial_response_id:
            print("âŒ è¯·å…ˆæå–æŠ¥å‘Šä¿¡æ¯åå†è¿›å…¥å¯¹è¯æ¨¡å¼")
            return
        
        print("\n" + "="*50)
        print("ğŸ’¬ è¿›å…¥å¯¹è¯æ¨¡å¼")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model}")
        print("="*50)
        print("æ‚¨ç°åœ¨å¯ä»¥è¯¢é—®å…³äºè¿™ä»½çŸ¿å±±æŠ¥å‘Šçš„ä»»ä½•é—®é¢˜ã€‚")
        print("è¾“å…¥ 'exit' æˆ– 'é€€å‡º' ç»“æŸå¯¹è¯ã€‚")
        print("="*50)
        
        previous_response_id = self.initial_response_id
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ™‹ æ‚¨çš„é—®é¢˜: ").strip()
                
                # æ£€æŸ¥æ˜¯å¦é€€å‡º
                if user_input.lower() in EXIT_COMMANDS:
                    print("\nğŸ‘‹ ç»“æŸå¯¹è¯ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
                    break
                
                if not user_input:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜")
                    continue
                
                # å‘é€é—®é¢˜å¹¶è·å–æµå¼å›ç­”
                print("\nğŸ¤– AIå›ç­”:")
                print("-" * 50)
                
                # ä½¿ç”¨æµå¼è¾“å‡º
                stream = self.client.responses.create(
                    model=self.model,
                    instructions=CONVERSATION_INSTRUCTIONS,
                    previous_response_id=previous_response_id,
                    input=user_input,
                    stream=True,
                )
                
                # æ”¶é›†å®Œæ•´å“åº”ä»¥è·å–response_id
                full_response = ""
                response_id = None
                
                for event in stream:
                    if event.type == 'response.output_text.delta':
                        print(event.delta, end='', flush=True)
                        full_response += event.delta
                    elif event.type == 'response.done':
                        # è·å–response_idç”¨äºä¸‹ä¸€è½®å¯¹è¯
                        response_id = event.response.id
                
                print("\n" + "-" * 50)
                
                # æ›´æ–°å¯¹è¯ID
                if response_id:
                    previous_response_id = response_id
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­å¯¹è¯")
                break
            except Exception as e:
                print(f"\nâŒ å¯¹è¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                print("æ‚¨å¯ä»¥å°è¯•é‡æ–°æé—®æˆ–é€€å‡ºå¯¹è¯ã€‚")
    
    def cleanup(self):
        """æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        if self.file_id:
            try:
                self.client.files.delete(self.file_id)
                print("ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºç°è­¦å‘Š: {e}")


# ========== ç”¨æˆ·äº¤äº’å‡½æ•° ==========
def select_model(models: List[str], prompt: str) -> str:
    """é€šç”¨çš„æ¨¡å‹é€‰æ‹©å‡½æ•°"""
    print(f"\n{prompt}")
    for i, model in enumerate(models, 1):
        print(f"{i}. {model}")
    print(f"{len(models)+1}. è‡ªå®šä¹‰æ¨¡å‹åç§°")
    
    while True:
        choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)+1}): ").strip()
        try:
            choice_num = int(choice)
            if 1 <= choice_num <= len(models):
                return models[choice_num - 1]
            elif choice_num == len(models) + 1:
                custom_model = input("è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°: ").strip()
                if custom_model:
                    return custom_model
            else:
                print(f"âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-{len(models)+1}")
        except ValueError:
            print(f"âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­— 1-{len(models)+1}")


def get_user_choice() -> Tuple[str, str]:
    """è·å–ç”¨æˆ·é€‰æ‹©çš„APIæä¾›å•†å’Œæ¨¡å‹"""
    print("\nğŸ¤– è¯·é€‰æ‹©AIæä¾›å•†:")
    print("1. Gemini (Google) - ä»…æ”¯æŒä¿¡æ¯æå–")
    print("2. OpenAI - æ”¯æŒä¿¡æ¯æå–å’Œæµå¼å¯¹è¯åŠŸèƒ½")
    
    while True:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-2): ").strip()
        if choice == "1":
            provider = "gemini"
            model = select_model(GEMINI_MODELS, "ğŸ“‹ Gemini å¯ç”¨æ¨¡å‹:")
            break
        elif choice == "2":
            provider = "openai"
            model = select_model(OPENAI_MODELS, "ğŸ“‹ OpenAI å¯ç”¨æ¨¡å‹:")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
    
    return provider, model


def create_extractor(provider: str = None, model: str = None, **kwargs) -> BaseMiningReportExtractor:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæå–å™¨å®ä¾‹"""
    if provider is None or model is None:
        provider, model = get_user_choice()
    
    print(f"\nğŸ”§ åˆ›å»ºæå–å™¨: {provider} - {model}")
    
    if provider == "gemini":
        return GeminiMiningReportExtractor(model=model, **kwargs)
    elif provider == "openai":
        return OpenAIMiningReportExtractorWithStreamConversation(model=model, **kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")


def get_pdf_file() -> str:
    """è·å–PDFæ–‡ä»¶è·¯å¾„"""
    while True:
        file_path = input("\nğŸ“ è¯·è¾“å…¥PDFæ–‡ä»¶è·¯å¾„: ").strip()
        # å»é™¤å¯èƒ½çš„å¼•å·
        if file_path.startswith('"') and file_path.endswith('"'):
            file_path = file_path[1:-1]
        
        if pathlib.Path(file_path).exists():
            return file_path
        else:
            print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")


def ask_yes_no(prompt: str) -> bool:
    """é€šç”¨çš„æ˜¯/å¦è¯¢é—®å‡½æ•°"""
    while True:
        choice = input(f"\n{prompt} (y/n): ").strip().lower()
        if choice in CONFIRM_CHOICES:
            return True
        elif choice in DENY_CHOICES:
            return False
        else:
            print("âŒ æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ y æˆ– n")


# ========== ä¸»å‡½æ•° ==========
def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼ä½¿ç”¨"""
    print("ğŸ”ï¸  çŸ¿å±±å‚¨é‡æ ¸å®æŠ¥å‘Šä¿¡æ¯æå–å·¥å…·")
    print("="*50)
    
    extractor = None
    try:
        # è·å–ç”¨æˆ·é€‰æ‹©
        provider, model = get_user_choice()
        extractor = create_extractor(provider, model)
        
        # è·å–æ–‡ä»¶è·¯å¾„
        pdf_file = get_pdf_file()
        
        # å¤„ç†æ–‡ä»¶
        print(f"\nğŸš€ å¼€å§‹å¤„ç†çŸ¿å±±æŠ¥å‘Š: {pathlib.Path(pdf_file).name}")
        result = extractor.extract_from_file(pdf_file)
        
        # æ˜¾ç¤ºç»“æœ
        extractor.print_summary(result)
        
        # ä¿å­˜ç»“æœ
        output_path = pathlib.Path(pdf_file).stem + "_result.json"
        extractor.save_result(result, output_path)
        
        print("\nğŸ‰ ä¿¡æ¯æå–å®Œæˆï¼")
        
        # å¦‚æœæ˜¯OpenAIï¼Œè¯¢é—®æ˜¯å¦è¿›å…¥å¯¹è¯æ¨¡å¼
        if provider == "openai" and isinstance(extractor, OpenAIMiningReportExtractorWithStreamConversation):
            if ask_yes_no("ğŸ’¬ æ˜¯å¦è¿›å…¥æé—®ç¯èŠ‚ï¼Ÿ"):
                extractor.start_conversation()
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†èµ„æº
        if extractor and isinstance(extractor, OpenAIMiningReportExtractorWithStreamConversation):
            extractor.cleanup()


if __name__ == "__main__":
    main() 